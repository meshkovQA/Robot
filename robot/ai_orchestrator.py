from curses import raw
import json
import logging
from openai import OpenAI
from datetime import datetime
from pathlib import Path
from robot.ai_agent.speech_handler import SpeechHandler
from robot.ai_agent.vision_analyzer import VisionAnalyzer
from robot.ai_agent.audio_manager import AudioManager
from robot.ai_agent.sensor_status_reporter import SensorStatusReporter


class AIOrchestrater:
    """
    –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π AI –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä —Ä–æ–±–æ—Ç–∞
    –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É –≤—Å–µ—Ö AI –∞–≥–µ–Ω—Ç–æ–≤ –∏ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏—è
    """

    def __init__(self, camera=None, robot_controller=None, ai_detector=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞
        :param camera: —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –æ–±—ä–µ–∫—Ç –∫–∞–º–µ—Ä—ã
        :param robot_controller: —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä —Ä–æ–±–æ—Ç–∞  
        :param ai_detector: —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π SimpleAIDetector
        """
        self.config = self._load_config()
        self.camera = camera
        self.robot = robot_controller
        self.ai_detector = ai_detector

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–≥–µ–Ω—Ç–æ–≤
        self.speech = None
        self.vision = None
        self.audio_manager = None
        self.wake_word_service = None
        self.openai_client = None

        self.sensor_reporter = SensorStatusReporter()

        self._initialize_agents()

        # –ò—Å—Ç–æ—Ä–∏—è –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç
        self.conversation_history = []
        self.current_context = {}

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
        self._load_system_prompts()

        logging.info("üß† AI –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def _load_config(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é AI"""
        import os

        config_path = Path("data/ai_config.json")

        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        logging.info("üìÑ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è AI –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

        # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º API –∫–ª—é—á –∏–∑ environment –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        env_api_key = os.getenv('OPENAI_API_KEY')
        if env_api_key:
            config['openai_api_key'] = env_api_key
            logging.info(
                "üîë OpenAI API –∫–ª—é—á –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ environment –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π")

        return config

    def _load_system_prompts(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        prompts_file = Path("data/system_prompts.json")

        with open(prompts_file, 'r', encoding='utf-8') as f:
            self.system_prompts = json.load(f)

        logging.info(
            f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.system_prompts)} —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤")

    def _initialize_agents(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö AI –∞–≥–µ–Ω—Ç–æ–≤"""

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞
        if not self.config:
            logging.error("‚ùå –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è AI –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞! self.config = None")
            return

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á
        api_key = self.config.get('openai_api_key')
        if not api_key:
            logging.warning("‚ö†Ô∏è OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
            return

        # –°–æ–∑–¥–∞–µ–º OpenAI –∫–ª–∏–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏–π
        self.openai_client = OpenAI(api_key=api_key)

        # AudioManager (–≤—Å–µ–≥–¥–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–ª—è —Ç–µ—Å—Ç–æ–≤)
        try:
            self.audio_manager = AudioManager(self.config.get('audio', {}))
            logging.info("‚úÖ AudioManager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ AudioManager: {e}")

        # SpeechHandler (–¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è)
        if self.config.get('speech_enabled', True):
            try:
                self.speech = SpeechHandler(self.config)
                if self.audio_manager:
                    self.speech.audio_manager = self.audio_manager
                logging.info("‚úÖ SpeechHandler –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ SpeechHandler: {e}")

        # WakeWordService (–¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏)
        if self.config.get('wake_word_enabled', True) and api_key:
            try:
                from robot.ai_agent.wake_word_service import WakeWordService
                self.wake_word_service = WakeWordService(
                    self.config, ai_orchestrator=self)

                # –ê–í–¢–û–ó–ê–ü–£–°–ö WakeWordService
                if self.wake_word_service.start_service():
                    logging.info("üöÄ WakeWordService –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—â–µ–Ω")
                else:
                    logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å WakeWordService")

            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ WakeWordService: {e}")
                self.wake_word_service = None
        else:
            self.wake_word_service = None
            if not api_key:
                logging.warning(
                    "‚ö†Ô∏è WakeWordService –ø—Ä–æ–ø—É—â–µ–Ω: –Ω–µ—Ç OpenAI API –∫–ª—é—á–∞")

    def analyze_user_intent(self, user_text):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞"""
        user_text_lower = user_text.lower().strip()

        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è 'vision'
        vision_keywords = [
            '—á—Ç–æ —Ç—ã –≤–∏–¥–∏—à—å', '–æ–ø–∏—à–∏', '–æ–ø–∏—Å–∞—Ç—å', '–∫–∞–º–µ—Ä–∞',
            '—á—Ç–æ –ø–µ—Ä–µ–¥ —Ç–æ–±–æ–π', '–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ',
            '—á—Ç–æ –Ω–∞ —ç–∫—Ä–∞–Ω–µ'
        ]

        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Å—Ç–∞—Ç—É—Å–∞ –¥–∞—Ç—á–∏–∫–æ–≤
        full_status_keywords = [
            '–ø–æ–ª–Ω—ã–π —Å—Ç–∞—Ç—É—Å', '–ø–æ–ª–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞', '–ø—Ä–æ–≤–µ—Ä—å –≤—Å–µ —Å–∏—Å—Ç–µ–º—ã',
            '–æ—Ç—á–µ—Ç –ø–æ –≤—Å–µ–º –¥–∞—Ç—á–∏–∫–∞–º', '–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –≤—Å–µ—Ö —Å–∏—Å—Ç–µ–º'
        ]

        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ç—É—Å–∞
        quick_status_keywords = [
            '–±—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ç—É—Å', '–∫—Ä–∞—Ç–∫–∏–π —Å—Ç–∞—Ç—É—Å', '—Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ä–æ–±–æ—Ç–∞', '—Å–≤–æ–¥–∫–∞'
        ]

        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
        alerts_keywords = [
            '–µ—Å—Ç—å –ª–∏ –ø—Ä–æ–±–ª–µ–º—ã', '–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è', '—Ç—Ä–µ–≤–æ–≥–∏', '–æ–ø–∞—Å–Ω–æ—Å—Ç—å', '–æ—à–∏–±–∫–∏', '–Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–∏'
        ]

        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–∞—Ç—á–∏–∫–æ–≤
        sensors_specific_keywords = [
            '–¥–∞—Ç—á–∏–∫–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è', '–ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏—è', '—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞', '–≤–ª–∞–∂–Ω–æ—Å—Ç—å',
            '—ç–Ω–∫–æ–¥–µ—Ä—ã', '—Å–∫–æ—Ä–æ—Å—Ç—å –∫–æ–ª–µ—Å', '–æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è', '–Ω–∞–∫–ª–æ–Ω', '—Ä–æ–±–æ—Ä—É–∫–∞'
        ]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ 'vision'
        for keyword in vision_keywords:
            if keyword in user_text_lower:
                logging.info(
                    f"üéØ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ 'vision' –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É: '{keyword}'")
                return 'vision'

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ 'status_full'
        for keyword in full_status_keywords:
            if keyword in user_text_lower:
                logging.info(
                    f"üéØ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ 'status_full' –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É: '{keyword}'")
                return 'status_full'

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ 'status_quick'
        for keyword in quick_status_keywords:
            if keyword in user_text_lower:
                logging.info(
                    f"üéØ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ 'status_quick' –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É: '{keyword}'")
                return 'status_quick'

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ 'status_alerts'
        for keyword in alerts_keywords:
            if keyword in user_text_lower:
                logging.info(
                    f"üéØ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ 'status_alerts' –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É: '{keyword}'")
                return 'status_alerts'

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ 'status_specific'
        for keyword in sensors_specific_keywords:
            if keyword in user_text_lower:
                logging.info(
                    f"üéØ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ 'status_specific' –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É: '{keyword}'")
                return 'status_specific'

        # –ï—Å–ª–∏ –Ω–∏–∫–∞–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã - —ç—Ç–æ –æ–±—ã—á–Ω—ã–π —á–∞—Ç
        logging.info("üéØ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ 'chat' (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)")
        return 'chat'

    def get_sensor_context(self):
        """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –¥–∞—Ç—á–∏–∫–æ–≤ –∏ —Å–∏—Å—Ç–µ–º —Ä–æ–±–æ—Ç–∞"""
        context = {
            "timestamp": datetime.now().isoformat(),
            "robot_systems": {}
        }

        # –î–∞–Ω–Ω—ã–µ —Å —Ä–æ–±–æ—Ç–∞
        if self.robot:
            try:
                robot_status = self.robot.get_status()
                context["robot_systems"].update({
                    "status": robot_status.get("status", "unknown"),
                    "battery_voltage": robot_status.get("battery_voltage"),
                    "sensors": robot_status.get("sensors", {}),
                    "movement": robot_status.get("movement", "stopped")
                })
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ —Ä–æ–±–æ—Ç–∞: {e}")

        # –°—Ç–∞—Ç—É—Å –∫–∞–º–µ—Ä—ã
        if self.camera:
            try:
                camera_status = self.camera.get_status()
                context["camera"] = {
                    "available": camera_status.get("available", False),
                    "connected": camera_status.get("connected", False),
                    "resolution": camera_status.get("resolution", "unknown")
                }
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –∫–∞–º–µ—Ä—ã: {e}")

        # –ê—É–¥–∏–æ —Å–∏—Å—Ç–µ–º–∞
        if self.audio_manager:
            try:
                devices = self.audio_manager.get_audio_devices_info()
                context["audio"] = {
                    "microphones_count": len(devices.get("microphones", [])),
                    "speakers_count": len(devices.get("speakers", [])),
                    "microphone_selected": devices.get("selected_microphone") is not None,
                    "speaker_selected": devices.get("selected_speaker") is not None
                }
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –∞—É–¥–∏–æ: {e}")

        return context

    def smart_process_request(self, audio_file=None, text=None):
        """
        –ì–õ–ê–í–ù–´–ô –º–µ—Ç–æ–¥ - —É–º–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ª—é–±–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –∏ –≤—ã–±–∏—Ä–∞–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
        """
        try:
            # 1. –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            if audio_file:
                if not self.speech:
                    return {"error": "–ì–æ–ª–æ—Å–æ–≤–æ–π –º–æ–¥—É–ª—å –Ω–µ –∞–∫—Ç–∏–≤–µ–Ω"}

                user_text = self.speech.transcribe_audio(audio_file)
                if not user_text:
                    return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å"}

            elif text:
                user_text = text
            else:
                return {"error": "–ù–µ—Ç –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"}

            logging.info(f"üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: '{user_text}'")

            # 2. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–º–µ—Ä–µ–Ω–∏–µ
            intent = self.analyze_user_intent(user_text)
            logging.info(f"üéØ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ: {intent}")

            # 3. –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∏—Ä—É–µ–º –Ω–∞ –Ω—É–∂–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
            if intent == 'vision':
                return self._handle_vision_request(user_text, audio_file is not None)

            elif intent == 'status':
                return self._handle_status_request(user_text, audio_file is not None)

            else:  # intent == 'chat'
                return self._handle_chat_request(user_text, audio_file is not None)

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —É–º–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return {"error": str(e)}

    def _handle_vision_request(self, user_text, is_voice=False):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ —á—Ç–æ –≤–∏–¥–∏—Ç —Ä–æ–±–æ—Ç"""
        if not self.vision:
            response_text = "–ò–∑–≤–∏–Ω–∏, –º–æ–¥—É–ª—å –∑—Ä–µ–Ω–∏—è –Ω–µ –∞–∫—Ç–∏–≤–µ–Ω"
        else:
            vision_result = self.vision.analyze_current_view()
            if vision_result.get("success"):
                response_text = vision_result["description"]

                # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
                extra_data = {
                    "vision_data": vision_result,
                    "detected_objects": vision_result.get("detected_objects", [])
                }
            else:
                response_text = "–ù–µ –º–æ–≥—É –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∫–∞–º–µ—Ä—ã"
                extra_data = {}

        tts_instructions = None
        if is_voice and self.config.get('tts_instructions', {}).get('vision'):
            tts_instructions = self.config['tts_instructions']['vision']

        return self._create_response(
            user_text=user_text,
            ai_response=response_text,
            intent='vision',
            is_voice=is_voice,
            extra_data=extra_data,
            tts_instructions=tts_instructions
        )

    def _handle_status_request(self, user_text, is_voice=False, status_type='status'):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Ä–æ–±–æ—Ç–∞ —á–µ—Ä–µ–∑ sensor_reporter"""
        try:

            if not self.robot:
                response_text = "–ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä —Ä–æ–±–æ—Ç–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
                return self._create_response(
                    user_text=user_text,
                    ai_response=response_text,
                    intent='status_error',
                    is_voice=is_voice,
                    extra_data={"error": "robot_unavailable"}
                )

            robot_status = self.robot.get_status()

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å—Ç–∞—Ç—É—Å–∞ –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –æ—Ç—á–µ—Ç
            if status_type == 'status_full':
                response_text = self.sensor_reporter.get_full_status_text(
                    robot_status)
                logging.info("üìä –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –ø–æ–ª–Ω—ã–π —Å—Ç–∞—Ç—É—Å –¥–∞—Ç—á–∏–∫–æ–≤")

            elif status_type == 'status_quick':
                response_text = self.sensor_reporter.get_quick_status_text(
                    robot_status)
                logging.info("‚ö° –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –±—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ç—É—Å")

            elif status_type == 'status_alerts':
                response_text = self.sensor_reporter.get_alerts_text(
                    robot_status)
                if not response_text.strip():
                    response_text = "–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –Ω–µ—Ç, –≤—Å–µ —Å–∏—Å—Ç–µ–º—ã —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ"
                logging.info("üö® –ü—Ä–æ–≤–µ—Ä–µ–Ω—ã –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã")

            elif status_type == 'status_specific':
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞—Ç—á–∏–∫–∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞—é—Ç—Å—è
                user_text_lower = user_text.lower()

                if '—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä' in user_text_lower or '–≤–ª–∞–∂–Ω–æ—Å—Ç' in user_text_lower:
                    sections = ['environment']
                elif '–ø—Ä–µ–ø—è—Ç—Å—Ç–≤' in user_text_lower or '—Ä–∞—Å—Å—Ç–æ—è–Ω' in user_text_lower:
                    sections = ['distances']
                elif '–¥–≤–∏–∂–µ–Ω–∏' in user_text_lower or '—Å–∫–æ—Ä–æ—Å—Ç' in user_text_lower or '—ç–Ω–∫–æ–¥–µ—Ä' in user_text_lower:
                    sections = ['motion']
                elif '–∫–∞–º–µ—Ä' in user_text_lower:
                    sections = ['camera']
                elif '—Ä–æ–±–æ—Ä—É–∫' in user_text_lower or '—Ä—É–∫' in user_text_lower:
                    sections = ['arm']
                elif '–Ω–∞–∫–ª–æ–Ω' in user_text_lower or '–æ—Ä–∏–µ–Ω—Ç–∞—Ü' in user_text_lower:
                    sections = ['imu']
                else:
                    sections = None

                response_text = self.sensor_reporter.get_full_status_text(
                    robot_status, sections)
                logging.info(f"üéØ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π —Å—Ç–∞—Ç—É—Å: {sections}")

            else:
                # Fallback - –±—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ç—É—Å
                response_text = self.sensor_reporter.get_quick_status_text(
                    robot_status)
                logging.info("üìã –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Å—Ç–∞—Ç—É—Å")

            # TTS –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏–∑ ai_config.json
            tts_instructions = None
            if is_voice and self.config.get('tts_instructions', {}).get('status'):
                tts_instructions = self.config['tts_instructions']['status']

            return self._create_response(
                user_text=user_text,
                ai_response=response_text,
                intent=status_type,
                is_voice=is_voice,
                extra_data={
                    "status_type": status_type,
                    "sensor_data_available": self.robot is not None
                },
                tts_instructions=tts_instructions
            )

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞—Ç—É—Å–∞ –¥–∞—Ç—á–∏–∫–æ–≤: {e}")
            return self._create_response(
                user_text=user_text,
                ai_response="–ù–µ –º–æ–≥—É –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å–∏—Å—Ç–µ–º",
                intent='status_error',
                is_voice=is_voice,
                extra_data={"error": str(e)}
            )

    def _handle_chat_request(self, user_text, is_voice=False):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—ã—á–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        if not self.speech:
            ai_response = "–ú–æ–¥—É–ª—å –æ–±—â–µ–Ω–∏—è –Ω–µ –∞–∫—Ç–∏–≤–µ–Ω"
        else:
            # –ü—Ä–æ–º–ø—Ç –∏–∑ system_prompts.json
            system_prompt = self.system_prompts['chat']
            ai_response = self.speech.generate_response(
                user_text, system_prompt=system_prompt)

        # TTS –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏–∑ ai_config.json
        tts_instructions = None
        if is_voice and self.config.get('tts_instructions', {}).get('chat'):
            tts_instructions = self.config['tts_instructions']['chat']

        return self._create_response(
            user_text=user_text,
            ai_response=ai_response,
            intent='chat',
            is_voice=is_voice,
            tts_instructions=tts_instructions
        )

    def _create_response(self, user_text, ai_response, intent, is_voice=False, extra_data=None, tts_instructions=None):
        """–°–æ–∑–¥–∞–Ω–∏–µ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
        response = {
            "success": True,
            "user_text": user_text,
            "ai_response": ai_response,
            "intent": intent,
            "timestamp": datetime.now().isoformat(),
            "is_voice": is_voice
        }

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        if extra_data:
            response.update(extra_data)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—É–¥–∏–æ –µ—Å–ª–∏ —ç—Ç–æ –≥–æ–ª–æ—Å–æ–≤–æ–π –∑–∞–ø—Ä–æ—Å
        if is_voice and self.speech and self.speech.audio_manager:
            try:
                audio_file = self.speech.text_to_speech(
                    ai_response, instructions=tts_instructions)
                response["audio_file"] = audio_file

                # –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º —Å—Ä–∞–∑—É –¥–ª—è —Å—Ç–∞—Ç—É—Å–Ω—ã—Ö –∫–æ–º–∞–Ω–¥
                if intent.startswith('status'):
                    speech_success = self.speech.audio_manager.play_audio(
                        audio_file)
                    response["speech_played"] = speech_success

                    if speech_success:
                        logging.info("üîä –°—Ç–∞—Ç—É—Å –¥–∞—Ç—á–∏–∫–æ–≤ –æ–∑–≤—É—á–µ–Ω")
                    else:
                        logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–∑–≤—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å")

            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        self._add_to_history(user_text, ai_response, intent)

        logging.info(f"ü§ñ –û—Ç–≤–µ—Ç ({intent}): '{ai_response}'")
        return response

    def voice_chat(self, recording_duration=5):
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ–±—â–µ–Ω–∏—è —Å —Ñ–∏–∑–∏—á–µ—Å–∫–∏–º–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏"""
        if not self.speech or not self.speech.audio_manager:
            return {"error": "–ê—É–¥–∏–æ —Å–∏—Å—Ç–µ–º–∞ –Ω–µ –∞–∫—Ç–∏–≤–Ω–∞"}

        try:
            logging.info("üé§ –ù–∞—á–∏–Ω–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç...")

            # 1. –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
            audio_file = self.speech.audio_manager.record_audio(
                duration_seconds=recording_duration,
                output_file=f"data/temp_voice_{int(datetime.now().timestamp())}.wav"
            )

            if not audio_file:
                return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –∞—É–¥–∏–æ"}

            # 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ —É–º–Ω—ã–π —Ä–æ—É—Ç–µ—Ä
            result = self.smart_process_request(audio_file=audio_file)

            if not result.get("success"):
                return result

            # 3. –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ –¥–∏–Ω–∞–º–∏–∫–∏
            if result.get("audio_file"):
                speech_success = self.speech.audio_manager.play_audio(
                    result["audio_file"])
                result["speech_played"] = speech_success

                if speech_success:
                    logging.info("üîä –û—Ç–≤–µ—Ç –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω —á–µ—Ä–µ–∑ –¥–∏–Ω–∞–º–∏–∫–∏")
                else:
                    logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –æ—Ç–≤–µ—Ç")

            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∑–∞–ø–∏—Å–∏
            try:
                Path(audio_file).unlink(missing_ok=True)
            except:
                pass

            return result

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —á–∞—Ç–∞: {e}")
            return {"error": str(e)}

    def speak_sensor_status(self, status_type='quick'):
        """
        –ü—Ä—è–º–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –¥–∞—Ç—á–∏–∫–æ–≤
        status_type: 'quick', 'full', 'alerts', –∏–ª–∏ —Å–ø–∏—Å–æ–∫ —Å–µ–∫—Ü–∏–π –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–≥–æ —Å—Ç–∞—Ç—É—Å–∞
        """
        try:
            if not self.speech or not self.speech.audio_manager:
                return {"error": "–ê—É–¥–∏–æ —Å–∏—Å—Ç–µ–º–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"}

            if not self.robot:
                return {"error": "–ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä —Ä–æ–±–æ—Ç–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"}

            robot_status = self.robot.get_status()

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—É—Å–∞
            if status_type == 'quick':
                status_text = self.sensor_reporter.get_quick_status_text(
                    robot_status)
            elif status_type == 'full':
                status_text = self.sensor_reporter.get_full_status_text(
                    robot_status)
            elif status_type == 'alerts':
                status_text = self.sensor_reporter.get_alerts_text(
                    robot_status)
                if not status_text.strip():
                    status_text = "–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –Ω–µ—Ç"
            elif isinstance(status_type, list):
                status_text = self.sensor_reporter.get_full_status_text(
                    robot_status, status_type)
            else:
                status_text = self.sensor_reporter.get_quick_status_text(
                    robot_status)

            if not status_text.strip():
                return {"error": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è"}

            # –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º
            tts_instructions = self.config.get(
                'tts_instructions', {}).get('status')
            audio_file = self.speech.text_to_speech(
                status_text, instructions=tts_instructions)

            if not audio_file:
                return {"error": "–û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏"}

            speech_success = self.speech.audio_manager.play_audio(audio_file)

            result = {
                "success": True,
                "status_type": status_type,
                "status_text": status_text,
                "audio_file": audio_file,
                "speech_played": speech_success,
                "timestamp": datetime.now().isoformat()
            }

            if speech_success:
                logging.info(f"üîä –°—Ç–∞—Ç—É—Å –¥–∞—Ç—á–∏–∫–æ–≤ '{status_type}' –æ–∑–≤—É—á–µ–Ω")
            else:
                logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ —Å—Ç–∞—Ç—É—Å")
                result["error"] = "–û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è"

            return result

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {e}")
            return {"error": str(e)}

    def _add_to_history(self, user_text, ai_response, intent):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–æ–≤"""
        entry = {
            "timestamp": datetime.now().isoformat(),
            "user_text": user_text,
            "ai_response": ai_response,
            "intent": intent
        }

        self.conversation_history.append(entry)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
        max_length = self.config.get('max_conversation_length', 10)
        if len(self.conversation_history) > max_length:
            self.conversation_history = self.conversation_history[-max_length:]

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)
        try:
            conversations_file = Path("data/conversations.json")
            conversations_file.parent.mkdir(exist_ok=True)

            with open(conversations_file, 'w', encoding='utf-8') as f:
                json.dump(self.conversation_history, f,
                          ensure_ascii=False, indent=2)

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏: {e}")

    # ====== –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–û–î–´ ======

    def chat(self, audio_file=None, text=None):
        """–ü—Ä–æ—Å—Ç–æ–µ –æ–±—â–µ–Ω–∏–µ (–æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)"""
        return self.smart_process_request(audio_file=audio_file, text=text)

    def describe_scene(self):
        """–û–ø–∏—Å–∞—Ç—å —á—Ç–æ –≤–∏–¥–∏—Ç —Ä–æ–±–æ—Ç (–æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)"""
        if not self.vision:
            return {"error": "–í–∏–¥–µ–æ –º–æ–¥—É–ª—å –æ—Ç–∫–ª—é—á–µ–Ω"}
        return self.vision.analyze_current_view()

    def get_status(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å AI –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
        return {
            "ai_orchestrator": {
                "initialized": True,
                "speech_available": self.speech is not None,
                "vision_available": self.vision is not None,
                "sensor_reporter_available": self.sensor_reporter is not None,
                "audio_hardware_available": (
                    self.audio_manager is not None and
                    self.audio_manager.microphone_index is not None and
                    self.audio_manager.speaker_index is not None
                ),
                "api_key_configured": bool(self.config.get('openai_api_key')),
                "conversation_entries": len(self.conversation_history),
                "config": {
                    "speech_enabled": self.config.get('speech_enabled', False),
                    "vision_enabled": self.config.get('vision_enabled', False),
                    "model": self.config.get('model', 'not set')
                }
            }
        }

    def update_config(self, new_config):
        """–û–±–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏ –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–≥–µ–Ω—Ç–æ–≤"""
        try:
            self.config.update(new_config)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            config_path = Path("data/ai_config.json")
            config_path.parent.mkdir(exist_ok=True)

            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, ensure_ascii=False, indent=2)

            # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–≥–µ–Ω—Ç–æ–≤ —Å –Ω–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
            self._initialize_agents()

            logging.info(
                "‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è AI –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –∏ –∞–≥–µ–Ω—Ç—ã –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
            return {"success": True, "message": "–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞"}

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            return {"error": str(e)}

    def get_conversation_history(self):
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–æ–≤"""
        return {
            "history": self.conversation_history,
            "total_entries": len(self.conversation_history)
        }

    def clear_conversation_history(self):
        """–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–æ–≤"""
        self.conversation_history = []
        try:
            conversations_file = Path("data/conversations.json")
            if conversations_file.exists():
                conversations_file.unlink()
            return {"success": True, "message": "–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–æ–≤ –æ—á–∏—â–µ–Ω–∞"}
        except Exception as e:
            return {"error": str(e)}
