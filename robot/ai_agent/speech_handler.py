import json
import logging
import openai
from datetime import datetime
from pathlib import Path
import time


class SpeechHandler:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ä–µ—á–∏ –¥–ª—è —Ä–æ–±–æ—Ç–∞
    –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è OpenAI Whisper STT, GPT –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤, OpenAI TTS
    """

    def __init__(self, config):
        self.config = config
        self.api_key = config.get('openai_api_key')

        if not self.api_key:
            raise ValueError("OpenAI API key –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")

        openai.api_key = self.api_key

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è OpenAI
        self.model = config.get('model', 'gpt-4o-mini')
        self.max_tokens = config.get('max_tokens', 1500)
        self.temperature = config.get('temperature', 0.7)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–µ—á–∏
        self.whisper_model = config.get('whisper_model', 'whisper-1')
        self.tts_model = config.get('tts_model', 'tts-1')
        # alloy, echo, fable, onyx, nova, shimmer
        self.tts_voice = config.get('voice', 'alloy')

        # –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–æ–≤
        self.conversation_file = Path("data/conversations.json")
        self.conversation_history = self._load_conversations()

        # AudioManager –±—É–¥–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω –∏–∑–≤–Ω–µ
        self.audio_manager = None

        # –°–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
        self.system_prompts = {
            'default': "–¢—ã —É–º–Ω—ã–π —Ä–æ–±–æ—Ç-–ø–æ–º–æ—â–Ω–∏–∫. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –¢—ã –º–æ–∂–µ—à—å –≤–∏–¥–µ—Ç—å —á–µ—Ä–µ–∑ –∫–∞–º–µ—Ä—É, —Å–ª—ã—à–∞—Ç—å —á–µ—Ä–µ–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω –∏ –¥–≤–∏–≥–∞—Ç—å—Å—è –ø–æ –¥–æ–º—É.",
            'vision': "–¢—ã —Ä–æ–±–æ—Ç —Å –∫–∞–º–µ—Ä–æ–π. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –æ–ø–∏—Å—ã–≤–∞–π —á—Ç–æ –≤–∏–¥–∏—à—å –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º.",
            'status': "–¢—ã —Ä–æ–±–æ—Ç-–¥–∏–∞–≥–Ω–æ—Å—Ç. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –æ—Ç–≤–µ—á–∞–π –ø–æ–Ω—è—Ç–Ω–æ –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å–∏—Å—Ç–µ–º.",
            'context': "–¢—ã —É–º–Ω—ã–π —Ä–æ–±–æ—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–π –≤—Å—é –¥–æ—Å—Ç—É–ø–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –¥–∞–≤–∞–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ, –Ω–æ –ø–æ–Ω—è—Ç–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã."
        }

        logging.info("üé§ SpeechHandler –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def _load_conversations(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–æ–≤"""
        try:
            if self.conversation_file.exists():
                with open(self.conversation_file, 'r', encoding='utf-8') as f:
                    conversations = json.load(f)
                logging.info(
                    f"üìñ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∏—Å—Ç–æ—Ä–∏—è: {len(conversations)} –∑–∞–ø–∏—Å–µ–π")
                return conversations
            return []
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∏–∞–ª–æ–≥–æ–≤: {e}")
            return []

    def _save_conversations(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–æ–≤"""
        try:
            self.conversation_file.parent.mkdir(exist_ok=True)
            with open(self.conversation_file, 'w', encoding='utf-8') as f:
                json.dump(self.conversation_history, f,
                          ensure_ascii=False, indent=2)
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–æ–≤: {e}")

    def transcribe_audio(self, audio_file_path):
        """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ OpenAI Whisper"""
        if not Path(audio_file_path).exists():
            logging.error(f"‚ùå –ê—É–¥–∏–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_file_path}")
            return None

        try:
            logging.info(f"üé§‚Üíüìù –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏: {audio_file_path}")

            with open(audio_file_path, 'rb') as audio_file:
                response = openai.audio.transcriptions.create(
                    model=self.whisper_model,
                    file=audio_file,
                    language="ru",  # –§–æ—Ä—Å–∏—Ä—É–µ–º —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
                    response_format="text",
                    temperature=0.0  # –î–ª—è –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
                )

            # OpenAI –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞–ø—Ä—è–º—É—é –ø—Ä–∏ response_format="text"
            if isinstance(response, str):
                transcribed_text = response.strip()
            else:
                transcribed_text = response.text.strip()

            if transcribed_text:
                logging.info(f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: '{transcribed_text}'")
                return transcribed_text
            else:
                logging.warning("‚ö†Ô∏è –ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è")
                return None

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ Whisper: {e}")
            return None

    def generate_response(self, user_message, intent='default', context_data=None):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ OpenAI GPT"""
        try:
            # –í—ã–±–∏—Ä–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –ø–æ —Ç–∏–ø—É –∑–∞–ø—Ä–æ—Å–∞
            system_prompt = self.system_prompts.get(
                intent, self.system_prompts['default'])

            # –°–æ–±–∏—Ä–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è OpenAI
            messages = [
                {"role": "system", "content": system_prompt}
            ]

            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
            if context_data:
                context_message = f"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: {json.dumps(context_data, ensure_ascii=False)}"
                messages.append({"role": "system", "content": context_message})

            # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–æ–≤ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π)
            recent_conversations = self.conversation_history[-5:] if self.conversation_history else [
            ]
            for conv in recent_conversations:
                if conv.get('user_message'):
                    messages.append(
                        {"role": "user", "content": conv['user_message']})
                if conv.get('ai_response'):
                    messages.append(
                        {"role": "assistant", "content": conv['ai_response']})

            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            messages.append({"role": "user", "content": user_message})

            logging.info(
                f"üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ ({intent}): '{user_message[:50]}...'")

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ OpenAI
            response = openai.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                frequency_penalty=0.1,  # –°–Ω–∏–∂–∞–µ–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
                presence_penalty=0.1    # –ü–æ–æ—â—Ä—è–µ–º –Ω–æ–≤—ã–µ —Ç–µ–º—ã
            )

            ai_response = response.choices[0].message.content.strip()

            if ai_response:
                logging.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç: '{ai_response[:100]}...'")
                return ai_response
            else:
                fallback_response = "–ò–∑–≤–∏–Ω–∏, —É –º–µ–Ω—è –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
                logging.warning("‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç GPT, –∏—Å–ø–æ–ª—å–∑—É—é fallback")
                return fallback_response

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ GPT: {e}")

            # Fallback –æ—Ç–≤–µ—Ç—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞
            fallback_responses = {
                'vision': "–ò–∑–≤–∏–Ω–∏, –Ω–µ –º–æ–≥—É —Å–µ–π—á–∞—Å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.",
                'status': "–ù–µ –º–æ–≥—É –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏—Å—Ç–µ–º–∞—Ö –≤ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç.",
                'action': "–ö–æ–º–∞–Ω–¥–∞ –ø–æ–Ω—è—Ç–∞, –Ω–æ —Å–µ–π—á–∞—Å –Ω–µ –º–æ–≥—É –µ—ë –≤—ã–ø–æ–ª–Ω–∏—Ç—å.",
                'context': "–ù–µ –º–æ–≥—É –ø—Ä–æ–≤–µ—Å—Ç–∏ –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–∏—Ç—É–∞—Ü–∏–∏ –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å.",
                'default': "–ò–∑–≤–∏–Ω–∏, —É –º–µ–Ω—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã. –ü–æ–ø—Ä–æ–±—É–π —á—É—Ç—å –ø–æ–∑–∂–µ."
            }

            return fallback_responses.get(intent, fallback_responses['default'])

    def text_to_speech(self, text, voice=None):
        """–°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ OpenAI TTS"""
        if not text or not text.strip():
            logging.warning("‚ö†Ô∏è –ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞")
            return None

        try:
            # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            clean_text = text.strip()

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ (OpenAI TTS –∏–º–µ–µ—Ç –ª–∏–º–∏—Ç—ã)
            if len(clean_text) > 4000:
                clean_text = clean_text[:4000] + "..."
                logging.warning(f"‚ö†Ô∏è –¢–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω –¥–æ 4000 —Å–∏–º–≤–æ–ª–æ–≤")

            logging.info(f"üìù‚Üíüîä –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏: '{clean_text[:50]}...'")

            response = openai.audio.speech.create(
                model=self.tts_model,
                voice=voice or self.tts_voice,
                input=clean_text,
                response_format="mp3",  # MP3 –±–æ–ª–µ–µ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π
                speed=1.0  # –ù–æ—Ä–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
            timestamp = int(time.time())
            audio_file = Path(f"data/temp/tts_response_{timestamp}.mp3")
            audio_file.parent.mkdir(parents=True, exist_ok=True)

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ
            with open(audio_file, 'wb') as f:
                for chunk in response.iter_bytes():
                    f.write(chunk)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size = audio_file.stat().st_size
            if file_size < 1000:
                logging.error(
                    f"‚ùå –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –º–∞–ª–µ–Ω—å–∫–∏–π TTS —Ñ–∞–π–ª: {file_size} –±–∞–π—Ç")
                return None

            logging.info(f"‚úÖ TTS —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {audio_file} ({file_size} –±–∞–π—Ç)")
            return str(audio_file)

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ TTS: {e}")
            return None

    def process_conversation(self, audio_file=None, text_message=None, intent='default', context_data=None):
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∏–∞–ª–æ–≥–∞: 
        –∞—É–¥–∏–æ ‚Üí —Ç–µ–∫—Å—Ç ‚Üí GPT ‚Üí TTS (–±–µ–∑ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è)
        """
        try:
            # 1. –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            if audio_file:
                user_text = self.transcribe_audio(audio_file)
                if not user_text:
                    return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å"}
            elif text_message:
                user_text = text_message
            else:
                return {"error": "–ù–µ—Ç –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"}

            # 2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            ai_response = self.generate_response(
                user_message=user_text,
                intent=intent,
                context_data=context_data
            )

            # 3. –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Ä–µ—á—å
            audio_response_file = self.text_to_speech(ai_response)

            # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
            conversation_entry = {
                "timestamp": datetime.now().isoformat(),
                "user_message": user_text,
                "ai_response": ai_response,
                "intent": intent,
                "audio_file": audio_response_file,
                "has_context": context_data is not None
            }

            self.conversation_history.append(conversation_entry)

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
            max_length = self.config.get('max_conversation_length', 10)
            if len(self.conversation_history) > max_length:
                self.conversation_history = self.conversation_history[-max_length:]

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
            self._save_conversations()

            result = {
                "success": True,
                "user_text": user_text,
                "ai_response": ai_response,
                "audio_file": audio_response_file,
                "intent": intent,
                "timestamp": conversation_entry["timestamp"]
            }

            logging.info(
                f"‚úÖ –î–∏–∞–ª–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞–Ω: '{user_text}' ‚Üí '{ai_response[:50]}...'")
            return result

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∏–∞–ª–æ–≥–∞: {e}")
            return {"error": str(e)}

    # ===== –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –° AUDIO MANAGER =====

    def record_and_transcribe(self, duration=5, use_voice_detection=False):
        """–ó–∞–ø–∏—Å–∞—Ç—å —Å —Ñ–∏–∑–∏—á–µ—Å–∫–æ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å"""
        if not self.audio_manager:
            logging.error("‚ùå AudioManager –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω")
            return None

        try:
            # –í—ã–±–∏—Ä–∞–µ–º –º–µ—Ç–æ–¥ –∑–∞–ø–∏—Å–∏
            if use_voice_detection:
                logging.info("üé§ –ó–∞–ø–∏—Å—å —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π –≥–æ–ª–æ—Å–∞...")
                audio_file = self.audio_manager.record_with_voice_detection(
                    max_duration=duration,
                    silence_timeout=2.0
                )
            else:
                logging.info(f"üé§ –ó–∞–ø–∏—Å—å {duration} —Å–µ–∫—É–Ω–¥...")
                audio_file = self.audio_manager.record_audio(duration)

            if not audio_file:
                logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –∞—É–¥–∏–æ")
                return None

            # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–µ
            text = self.transcribe_audio(audio_file)

            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            try:
                Path(audio_file).unlink(missing_ok=True)
            except:
                pass

            return text

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
            return None

    def speak_response(self, text, voice=None):
        """–°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ –∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ –¥–∏–Ω–∞–º–∏–∫–∏"""
        if not self.audio_manager:
            logging.error("‚ùå AudioManager –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω")
            return False

        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
            audio_file = self.text_to_speech(text, voice)
            if not audio_file:
                return False

            # –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º —á–µ—Ä–µ–∑ –¥–∏–Ω–∞–º–∏–∫–∏
            success = self.audio_manager.play_audio(audio_file)

            if success:
                logging.info(f"‚úÖ –†–µ—á—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∞: '{text[:50]}...'")
            else:
                logging.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ —Ä–µ—á—å")

            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —É–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            # Path(audio_file).unlink(missing_ok=True)

            return success

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è —Ä–µ—á–∏: {e}")
            return False

    def full_voice_interaction(self, recording_duration=5, use_voice_detection=False,
                               intent='default', context_data=None):
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å —Ñ–∏–∑–∏—á–µ—Å–∫–∏–º–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏:
        –º–∏–∫—Ä–æ—Ñ–æ–Ω ‚Üí Whisper ‚Üí GPT ‚Üí TTS ‚Üí –¥–∏–Ω–∞–º–∏–∫–∏
        """
        if not self.audio_manager:
            return {"error": "AudioManager –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω"}

        try:
            logging.info("üé§ü§ñüîä –ù–∞—á–∏–Ω–∞—é –ø–æ–ª–Ω—ã–π –≥–æ–ª–æ—Å–æ–≤–æ–π —Ü–∏–∫–ª...")

            # 1. –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
            user_text = self.record_and_transcribe(
                duration=recording_duration,
                use_voice_detection=use_voice_detection
            )

            if not user_text:
                return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –∏–ª–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å"}

            logging.info(f"üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–∫–∞–∑–∞–ª: '{user_text}'")

            # 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ AI
            response = self.process_conversation(
                text_message=user_text,
                intent=intent,
                context_data=context_data
            )

            if not response.get("success"):
                return response

            # 3. –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º –æ—Ç–≤–µ—Ç
            if response.get("audio_file"):
                speech_success = self.audio_manager.play_audio(
                    response["audio_file"])
                response["speech_played"] = speech_success

                if speech_success:
                    logging.info(
                        f"ü§ñ –†–æ–±–æ—Ç –æ—Ç–≤–µ—Ç–∏–ª: '{response['ai_response']}'")
                else:
                    logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –æ—Ç–≤–µ—Ç")

            return response

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª–Ω–æ–≥–æ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è: {e}")
            return {"error": str(e)}

    # ===== –£–ü–†–ê–í–õ–ï–ù–ò–ï –ò –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê =====

    def get_conversation_stats(self):
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∏–∞–ª–æ–≥–æ–≤"""
        if not self.conversation_history:
            return {"total": 0, "today": 0}

        try:
            total = len(self.conversation_history)
            today = 0

            today_date = datetime.now().date()
            for conv in self.conversation_history:
                try:
                    conv_date = datetime.fromisoformat(
                        conv["timestamp"]).date()
                    if conv_date == today_date:
                        today += 1
                except:
                    continue

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –Ω–∞–º–µ—Ä–µ–Ω–∏–π
            intent_stats = {}
            for conv in self.conversation_history:
                intent = conv.get('intent', 'unknown')
                intent_stats[intent] = intent_stats.get(intent, 0) + 1

            return {
                "total": total,
                "today": today,
                "intent_distribution": intent_stats,
                "last_conversation": self.conversation_history[-1]["timestamp"] if self.conversation_history else None
            }

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {"error": str(e)}

    def clear_conversation_history(self):
        """–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–æ–≤"""
        try:
            self.conversation_history = []
            self._save_conversations()
            logging.info("üóëÔ∏è –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–æ–≤ –æ—á–∏—â–µ–Ω–∞")
            return {"success": True, "message": "–ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞"}
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {e}")
            return {"error": str(e)}

    def export_conversations(self, format='json'):
        """–≠–∫—Å–ø–æ—Ä—Ç –¥–∏–∞–ª–æ–≥–æ–≤"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            if format.lower() == 'json':
                export_file = Path(
                    f"data/conversations_export_{timestamp}.json")
                with open(export_file, 'w', encoding='utf-8') as f:
                    json.dump(self.conversation_history, f,
                              ensure_ascii=False, indent=2)

            elif format.lower() == 'txt':
                export_file = Path(
                    f"data/conversations_export_{timestamp}.txt")
                with open(export_file, 'w', encoding='utf-8') as f:
                    for conv in self.conversation_history:
                        f.write(f"[{conv.get('timestamp', 'Unknown')}]\n")
                        f.write(
                            f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {conv.get('user_message', '')}\n")
                        f.write(f"–†–æ–±–æ—Ç: {conv.get('ai_response', '')}\n")
                        f.write(f"–¢–∏–ø: {conv.get('intent', 'unknown')}\n")
                        f.write("-" * 50 + "\n\n")

            else:
                return {"error": "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç—ã: json, txt"}

            return {
                "success": True,
                "file": str(export_file),
                "entries": len(self.conversation_history)
            }

        except Exception as e:
            return {"error": str(e)}

    def test_speech_system(self):
        """–¢–µ—Å—Ç —Ä–µ—á–µ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã"""
        results = {
            "openai_api_test": False,
            "whisper_test": False,
            "gpt_test": False,
            "tts_test": False,
            "audio_hardware_test": False,
            "details": []
        }

        try:
            # 1. –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ OpenAI API
            try:
                response = openai.models.list()
                results["openai_api_test"] = True
                results["details"].append("‚úÖ OpenAI API –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
            except Exception as e:
                results["details"].append(f"‚ùå OpenAI API: {e}")

            # 2. –¢–µ—Å—Ç GPT
            if results["openai_api_test"]:
                try:
                    test_response = self.generate_response(
                        "–ü—Ä–∏–≤–µ—Ç, —ç—Ç–æ —Ç–µ—Å—Ç", intent='default')
                    if test_response and len(test_response) > 5:
                        results["gpt_test"] = True
                        results["details"].append("‚úÖ GPT –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç")
                    else:
                        results["details"].append(
                            "‚ùå GPT: –ø—É—Å—Ç–æ–π –∏–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç")
                except Exception as e:
                    results["details"].append(f"‚ùå GPT: {e}")

            # 3. –¢–µ—Å—Ç TTS
            if results["openai_api_test"]:
                try:
                    test_audio = self.text_to_speech("–¢–µ—Å—Ç —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏")
                    if test_audio and Path(test_audio).exists():
                        file_size = Path(test_audio).stat().st_size
                        if file_size > 1000:
                            results["tts_test"] = True
                            results["details"].append(
                                f"‚úÖ TTS —Ä–∞–±–æ—Ç–∞–µ—Ç ({file_size} –±–∞–π—Ç)")
                        else:
                            results["details"].append(
                                f"‚ùå TTS: —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π —Ñ–∞–π–ª ({file_size} –±–∞–π—Ç)")

                        # –£–¥–∞–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
                        Path(test_audio).unlink(missing_ok=True)
                    else:
                        results["details"].append(
                            "‚ùå TTS: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª")
                except Exception as e:
                    results["details"].append(f"‚ùå TTS: {e}")

            # 4. –¢–µ—Å—Ç –∞—É–¥–∏–æ hardware
            if self.audio_manager:
                try:
                    audio_test = self.audio_manager.test_audio_system()
                    if audio_test.get("overall_success"):
                        results["audio_hardware_test"] = True
                        results["details"].append("‚úÖ –ê—É–¥–∏–æ hardware —Ä–∞–±–æ—Ç–∞–µ—Ç")
                    else:
                        results["details"].append(
                            "‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã —Å –∞—É–¥–∏–æ hardware")
                        results["details"].extend(
                            audio_test.get("details", []))
                except Exception as e:
                    results["details"].append(f"‚ùå –ê—É–¥–∏–æ hardware —Ç–µ—Å—Ç: {e}")
            else:
                results["details"].append("‚ö†Ô∏è AudioManager –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω")

            # 5. –û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            total_tests = 4  # –ò—Å–∫–ª—é—á–∞–µ–º Whisper, —Ç–∞–∫ –∫–∞–∫ –Ω—É–∂–µ–Ω –∞—É–¥–∏–æ —Ñ–∞–π–ª
            passed_tests = sum([
                results["openai_api_test"],
                results["gpt_test"],
                results["tts_test"],
                results["audio_hardware_test"]
            ])

            results["overall_success"] = passed_tests >= 3
            results["score"] = f"{passed_tests}/{total_tests}"

            logging.info(f"üß™ –¢–µ—Å—Ç —Ä–µ—á–µ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã: {results['score']}")

            return results

        except Exception as e:
            logging.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            results["details"].append(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            return results

    def get_available_voices(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤ TTS"""
        return {
            "voices": [
                {"id": "alloy", "name": "Alloy",
                    "description": "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å"},
                {"id": "echo", "name": "Echo", "description": "–ú—É–∂—Å–∫–æ–π –≥–æ–ª–æ—Å"},
                {"id": "fable", "name": "Fable", "description": "–ë—Ä–∏—Ç–∞–Ω—Å–∫–∏–π –∞–∫—Ü–µ–Ω—Ç"},
                {"id": "onyx", "name": "Onyx",
                    "description": "–ì–ª—É–±–æ–∫–∏–π –º—É–∂—Å–∫–æ–π –≥–æ–ª–æ—Å"},
                {"id": "nova", "name": "Nova",
                    "description": "–ú–æ–ª–æ–¥–æ–π –∂–µ–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å"},
                {"id": "shimmer", "name": "Shimmer",
                    "description": "–ú—è–≥–∫–∏–π –∂–µ–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å"}
            ],
            "current_voice": self.tts_voice,
            "models": ["tts-1", "tts-1-hd"]
        }

    def set_voice(self, voice_id):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≥–æ–ª–æ—Å –¥–ª—è TTS"""
        available_voices = ["alloy", "echo",
                            "fable", "onyx", "nova", "shimmer"]

        if voice_id in available_voices:
            self.tts_voice = voice_id
            logging.info(f"üîä –ì–æ–ª–æ—Å –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: {voice_id}")
            return {"success": True, "voice": voice_id}
        else:
            return {"error": f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –≥–æ–ª–æ—Å. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {available_voices}"}

    def get_status(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Ä–µ—á–µ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã"""
        return {
            "speech_handler": {
                "initialized": True,
                "api_key_configured": bool(self.api_key),
                "model": self.model,
                "tts_voice": self.tts_voice,
                "conversation_entries": len(self.conversation_history),
                "audio_manager_connected": self.audio_manager is not None,
                "last_conversation": (
                    self.conversation_history[-1]["timestamp"]
                    if self.conversation_history else None
                )
            }
        }
