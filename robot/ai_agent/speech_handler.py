# robot/ai_agent/speech_handler.py

import json
import logging
from openai import OpenAI
import os
from datetime import datetime
from pathlib import Path
import time
from .yandex_stt_client import YandexSTTClient


class SpeechHandler:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ä–µ—á–∏ –¥–ª—è —Ä–æ–±–æ—Ç–∞
    –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è OpenAI Whisper STT, GPT –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤, OpenAI TTS
    """

    def __init__(self, config):
        self.config = config

        self._provider = (self.config.get("speech", {})
                          or {}).get("provider", "openai")

        yc = (self.config.get("speech", {}) or {}).get("yandex", {}) or {}
        self._yandex_client = None

        try:
            if self._provider == "yandex":
                auth = (yc.get("auth") or "api_key").lower()
                api_key = os.getenv(
                    "YANDEX_API_KEY") if auth == "api_key" else None
                iam_token = yc.get("iam_token") if auth == "iam" else None
                self._yandex_client = YandexSTTClient(
                    api_key=api_key,
                    iam_token=iam_token,
                    sample_rate=yc.get("sample_rate", 48000),
                    channels=yc.get("channels", 1),
                    profanity_filter=bool(yc.get("profanity_filter", True)),
                    model=yc.get("model", "general"),
                )
                logging.info("Yandex STT client initialized")
        except Exception as e:
            logging.error(f"Yandex STT init error: {e}")

        # –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á —Ç–æ–ª—å–∫–æ –∏–∑ environment –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        self.api_key = os.getenv('OPENAI_API_KEY')

        if not self.api_key:
            raise ValueError(
                "OpenAI API key –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY")

        # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç —Å –Ω–æ–≤—ã–º API
        self.client = OpenAI(api_key=self.api_key)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è OpenAI (–æ—Å—Ç–∞–µ—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å)
        self.model = config.get('model', 'gpt-4o-mini')
        self.max_tokens = config.get('max_tokens', 1500)
        self.temperature = config.get('temperature', 0.7)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–µ—á–∏ (–æ—Å—Ç–∞–µ—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å)
        self.whisper_model = config.get('whisper_model', 'whisper-1')
        self.tts_model = config.get('tts_model', 'tts-1')
        self.tts_voice = config.get('voice', 'alloy')

        # –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–æ–≤ (–æ—Å—Ç–∞–µ—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å)
        self.conversation_file = Path("data/conversations.json")
        self.conversation_history = self._load_conversations()

        # AudioManager –±—É–¥–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω –∏–∑–≤–Ω–µ
        self.audio_manager = None

        self._load_system_prompts()

        logging.info("üé§ SpeechHandler –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –Ω–æ–≤—ã–º OpenAI API")

    def _load_conversations(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–æ–≤"""
        try:
            if self.conversation_file.exists():
                with open(self.conversation_file, 'r', encoding='utf-8') as f:
                    conversations = json.load(f)
                logging.info(
                    f"üìñ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∏—Å—Ç–æ—Ä–∏—è: {len(conversations)} –∑–∞–ø–∏—Å–µ–π")
                return conversations
            return []
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∏–∞–ª–æ–≥–æ–≤: {e}")
            return []

    def _save_conversations(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–æ–≤"""
        try:
            self.conversation_file.parent.mkdir(exist_ok=True)
            with open(self.conversation_file, 'w', encoding='utf-8') as f:
                json.dump(self.conversation_history, f,
                          ensure_ascii=False, indent=2)
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–æ–≤: {e}")

    def _load_system_prompts(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        prompts_file = Path("data/system_prompts.json")

        with open(prompts_file, 'r', encoding='utf-8') as f:
            self.system_prompts = json.load(f)

        logging.info(
            f"üìÑ SpeechHandler –∑–∞–≥—Ä—É–∑–∏–ª {len(self.system_prompts)} –ø—Ä–æ–º–ø—Ç–æ–≤")

    def transcribe_audio(self, wav_path: str) -> str | None:
        logging.info(f"STT provider={self._provider} file={wav_path}")
        try:
            if self._provider == "yandex" and self._yandex_client:
                text = self._yandex_client.recognize_wav(wav_path) or None
                if text:
                    logging.info(f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ (Yandex): '{text}'")
                return text
            # --- —Ñ–æ–ª–±—ç–∫ –Ω–∞ OpenAI:
            text = self._transcribe_with_openai(wav_path)
            if text:
                logging.info(f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ (OpenAI): '{text}'")
            return text
        except Exception as e:
            logging.error(
                f"STT error ({self._provider}). Fallback to OpenAI. Reason: {e}")
            try:
                text = self._transcribe_with_openai(wav_path)
                if text:
                    logging.info(f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ (OpenAI —Ñ–æ–ª–±—ç–∫): '{text}'")
                return text
            except Exception as e2:
                logging.error(f"OpenAI STT failed: {e2}")
                return None

    def transcribe_with_openai(self, audio_file_path):
        """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ OpenAI Whisper"""
        if not Path(audio_file_path).exists():
            logging.error(f"‚ùå –ê—É–¥–∏–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_file_path}")
            return None

        try:
            logging.info(f"üé§‚Üíüìù –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏: {audio_file_path}")

            with open(audio_file_path, 'rb') as audio_file:
                response = self.client.audio.transcriptions.create(
                    model=self.whisper_model,  # –¢–µ–ø–µ—Ä—å —ç—Ç–æ gpt-4o-transcribe
                    file=audio_file,
                    language="ru",  # –§–æ—Ä—Å–∏—Ä—É–µ–º —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
                    response_format="text",
                    temperature=0.0,  # –î–ª—è –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
                )

            # OpenAI –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞–ø—Ä—è–º—É—é –ø—Ä–∏ response_format="text"
            if isinstance(response, str):
                transcribed_text = response.strip()
            else:
                transcribed_text = response.text.strip()

            if transcribed_text:
                logging.info(f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: '{transcribed_text}'")
                return transcribed_text
            else:
                logging.warning("‚ö†Ô∏è –ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è")
                return None

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ Whisper: {e}")
            return None

    def generate_response(self, user_message, context_data=None, system_prompt=None, intent=None):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ OpenAI GPT"""

        system_prompt = system_prompt or self.system_prompts['default']

        # –°–æ–±–∏—Ä–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è OpenAI
        messages = [
            {"role": "system", "content": system_prompt}
        ]

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
        if context_data:
            context_message = f"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: {json.dumps(context_data, ensure_ascii=False)}"
            messages.append({"role": "system", "content": context_message})

        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–æ–≤ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π)
        recent_conversations = self.conversation_history[-5:] if self.conversation_history else [
        ]
        for conv in recent_conversations:
            if conv.get('user_message'):
                messages.append(
                    {"role": "user", "content": conv['user_message']})
            if conv.get('ai_response'):
                messages.append(
                    {"role": "assistant", "content": conv['ai_response']})

        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        messages.append({"role": "user", "content": user_message})

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ OpenAI
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            max_tokens=self.max_tokens,
            temperature=self.temperature,
            frequency_penalty=0.1,  # –°–Ω–∏–∂–∞–µ–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
            presence_penalty=0.1    # –ü–æ–æ—â—Ä—è–µ–º –Ω–æ–≤—ã–µ —Ç–µ–º—ã
        )

        ai_response = response.choices[0].message.content.strip()

        if ai_response:
            logging.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç: '{ai_response[:100]}...'")
            return ai_response
        else:
            fallback_response = "–ò–∑–≤–∏–Ω–∏, —É –º–µ–Ω—è –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
            logging.warning("‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç GPT, –∏—Å–ø–æ–ª—å–∑—É—é fallback")
            return fallback_response

    def text_to_speech(self, text, voice=None, instructions=None):
        """–°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ OpenAI TTS"""
        if not text or not text.strip():
            logging.warning("‚ö†Ô∏è –ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞")
            return None

        try:
            # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            clean_text = text.strip()

            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è TTS
            tts_instructions = instructions
            if tts_instructions is None:
                tts_instructions = self.config.get('tts_instructions')
            if isinstance(tts_instructions, dict):
                tts_instructions = tts_instructions.get('default', "")

            if not isinstance(tts_instructions, str):
                tts_instructions = ""

            logging.info(
                f"üìù‚Üíüîä –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ (–Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å): '{clean_text[:50]}...'")

            response = self.client.audio.speech.create(
                model=self.tts_model,  # –¢–µ–ø–µ—Ä—å —ç—Ç–æ gpt-4o-mini-tts
                voice=voice or self.tts_voice,
                input=clean_text,
                response_format="mp3",
                speed=1.0,
                # –ù–û–í–ê–Ø –§–ò–ß–ê: –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è —Å—Ç–∏–ª—è —Ä–µ—á–∏
                instructions=tts_instructions
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
            timestamp = int(time.time())
            audio_file = Path(f"data/temp/tts_response_{timestamp}.mp3")
            audio_file.parent.mkdir(parents=True, exist_ok=True)

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ
            with open(audio_file, 'wb') as f:
                for chunk in response.iter_bytes():
                    f.write(chunk)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size = audio_file.stat().st_size
            if file_size < 1000:
                logging.error(
                    f"‚ùå –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –º–∞–ª–µ–Ω—å–∫–∏–π TTS —Ñ–∞–π–ª: {file_size} –±–∞–π—Ç")
                return None

            logging.info(f"‚úÖ TTS —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {audio_file} ({file_size} –±–∞–π—Ç)")
            return str(audio_file)

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ TTS: {e}")
            return None

    def process_conversation(self, audio_file=None, text_message=None, intent='default', context_data=None):
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∏–∞–ª–æ–≥–∞: 
        –∞—É–¥–∏–æ ‚Üí —Ç–µ–∫—Å—Ç ‚Üí GPT ‚Üí TTS (–±–µ–∑ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è)
        """
        try:
            # 1. –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            if audio_file:
                user_text = self.transcribe_audio(audio_file)
                if not user_text:
                    return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å"}
            elif text_message:
                user_text = text_message
            else:
                return {"error": "–ù–µ—Ç –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"}

            # 2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            ai_response = self.generate_response(
                user_message=user_text,
                intent=intent,
                context_data=context_data
            )

            # 3. –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Ä–µ—á—å
            audio_response_file = self.text_to_speech(ai_response)

            # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
            conversation_entry = {
                "timestamp": datetime.now().isoformat(),
                "user_message": user_text,
                "ai_response": ai_response,
                "intent": intent,
                "audio_file": audio_response_file,
                "has_context": context_data is not None
            }

            self.conversation_history.append(conversation_entry)

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
            max_length = self.config.get('max_conversation_length', 10)
            if len(self.conversation_history) > max_length:
                self.conversation_history = self.conversation_history[-max_length:]

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
            self._save_conversations()

            result = {
                "success": True,
                "user_text": user_text,
                "ai_response": ai_response,
                "audio_file": audio_response_file,
                "intent": intent,
                "timestamp": conversation_entry["timestamp"]
            }

            logging.info(
                f"‚úÖ –î–∏–∞–ª–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞–Ω: '{user_text}' ‚Üí '{ai_response[:50]}...'")
            return result

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∏–∞–ª–æ–≥–∞: {e}")
            return {"error": str(e)}

    # ===== –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –° AUDIO MANAGER =====

    def record_and_transcribe(self, duration=5, use_voice_detection=False):
        """–ó–∞–ø–∏—Å–∞—Ç—å —Å —Ñ–∏–∑–∏—á–µ—Å–∫–æ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å"""
        if not self.audio_manager:
            logging.error("‚ùå AudioManager –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω")
            return None

        try:
            # –í—ã–±–∏—Ä–∞–µ–º –º–µ—Ç–æ–¥ –∑–∞–ø–∏—Å–∏
            if use_voice_detection:
                logging.info("üé§ –ó–∞–ø–∏—Å—å —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π –≥–æ–ª–æ—Å–∞...")
                audio_file = self.audio_manager.record_with_voice_detection(
                    max_duration=duration,
                    silence_timeout=2.0
                )
            else:
                logging.info(f"üé§ –ó–∞–ø–∏—Å—å {duration} —Å–µ–∫—É–Ω–¥...")
                audio_file = self.audio_manager.record_audio(duration)

            if not audio_file:
                logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –∞—É–¥–∏–æ")
                return None

            # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–µ
            text = self.transcribe_audio(audio_file)

            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            try:
                Path(audio_file).unlink(missing_ok=True)
            except:
                pass

            return text

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
            return None

    def speak_response(self, text, voice=None):
        """–°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ –∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ –¥–∏–Ω–∞–º–∏–∫–∏"""
        if not self.audio_manager:
            logging.error("‚ùå AudioManager –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω")
            return False

        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
            audio_file = self.text_to_speech(text, voice)
            if not audio_file:
                return False

            # –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º —á–µ—Ä–µ–∑ –¥–∏–Ω–∞–º–∏–∫–∏
            success = self.audio_manager.play_audio(audio_file)

            if success:
                logging.info(f"‚úÖ –†–µ—á—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∞: '{text[:50]}...'")
            else:
                logging.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ —Ä–µ—á—å")

            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —É–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            # Path(audio_file).unlink(missing_ok=True)

            return success

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è —Ä–µ—á–∏: {e}")
            return False

    def full_voice_interaction(self, recording_duration=5, use_voice_detection=False,
                               intent='default', context_data=None):
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å —Ñ–∏–∑–∏—á–µ—Å–∫–∏–º–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏:
        –º–∏–∫—Ä–æ—Ñ–æ–Ω ‚Üí Whisper ‚Üí GPT ‚Üí TTS ‚Üí –¥–∏–Ω–∞–º–∏–∫–∏
        """
        if not self.audio_manager:
            return {"error": "AudioManager –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω"}

        try:
            logging.info("üé§ü§ñüîä –ù–∞—á–∏–Ω–∞—é –ø–æ–ª–Ω—ã–π –≥–æ–ª–æ—Å–æ–≤–æ–π —Ü–∏–∫–ª...")

            # 1. –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
            user_text = self.record_and_transcribe(
                duration=recording_duration,
                use_voice_detection=use_voice_detection
            )

            if not user_text:
                return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –∏–ª–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å"}

            logging.info(f"üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–∫–∞–∑–∞–ª: '{user_text}'")

            # 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ AI
            response = self.process_conversation(
                text_message=user_text,
                intent=intent,
                context_data=context_data
            )

            if not response.get("success"):
                return response

            # 3. –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º –æ—Ç–≤–µ—Ç
            if response.get("audio_file"):
                speech_success = self.audio_manager.play_audio(
                    response["audio_file"])
                response["speech_played"] = speech_success

                if speech_success:
                    logging.info(
                        f"ü§ñ –†–æ–±–æ—Ç –æ—Ç–≤–µ—Ç–∏–ª: '{response['ai_response']}'")
                else:
                    logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –æ—Ç–≤–µ—Ç")

            return response

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª–Ω–æ–≥–æ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è: {e}")
            return {"error": str(e)}

    # ===== –£–ü–†–ê–í–õ–ï–ù–ò–ï –ò –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê =====

    def get_conversation_stats(self):
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∏–∞–ª–æ–≥–æ–≤"""
        if not self.conversation_history:
            return {"total": 0, "today": 0}

        try:
            total = len(self.conversation_history)
            today = 0

            today_date = datetime.now().date()
            for conv in self.conversation_history:
                try:
                    conv_date = datetime.fromisoformat(
                        conv["timestamp"]).date()
                    if conv_date == today_date:
                        today += 1
                except:
                    continue

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –Ω–∞–º–µ—Ä–µ–Ω–∏–π
            intent_stats = {}
            for conv in self.conversation_history:
                intent = conv.get('intent', 'unknown')
                intent_stats[intent] = intent_stats.get(intent, 0) + 1

            return {
                "total": total,
                "today": today,
                "intent_distribution": intent_stats,
                "last_conversation": self.conversation_history[-1]["timestamp"] if self.conversation_history else None
            }

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {"error": str(e)}

    def clear_conversation_history(self):
        """–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–æ–≤"""
        try:
            self.conversation_history = []
            self._save_conversations()
            logging.info("üóëÔ∏è –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–æ–≤ –æ—á–∏—â–µ–Ω–∞")
            return {"success": True, "message": "–ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞"}
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {e}")
            return {"error": str(e)}

    def export_conversations(self, format='json'):
        """–≠–∫—Å–ø–æ—Ä—Ç –¥–∏–∞–ª–æ–≥–æ–≤"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            if format.lower() == 'json':
                export_file = Path(
                    f"data/conversations_export_{timestamp}.json")
                with open(export_file, 'w', encoding='utf-8') as f:
                    json.dump(self.conversation_history, f,
                              ensure_ascii=False, indent=2)

            elif format.lower() == 'txt':
                export_file = Path(
                    f"data/conversations_export_{timestamp}.txt")
                with open(export_file, 'w', encoding='utf-8') as f:
                    for conv in self.conversation_history:
                        f.write(f"[{conv.get('timestamp', 'Unknown')}]\n")
                        f.write(
                            f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {conv.get('user_message', '')}\n")
                        f.write(f"–†–æ–±–æ—Ç: {conv.get('ai_response', '')}\n")
                        f.write(f"–¢–∏–ø: {conv.get('intent', 'unknown')}\n")
                        f.write("-" * 50 + "\n\n")

            else:
                return {"error": "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç—ã: json, txt"}

            return {
                "success": True,
                "file": str(export_file),
                "entries": len(self.conversation_history)
            }

        except Exception as e:
            return {"error": str(e)}

    def set_voice(self, voice_id):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≥–æ–ª–æ—Å –¥–ª—è TTS"""
        available_voices = ["alloy", "echo", "fable", "onyx", "nova", "shimmer",
                            "marin", "cedar"]  # ‚Üê‚Üê –î–û–ë–ê–í–õ–ï–ù–´ –ù–û–í–´–ï –ì–û–õ–û–°–ê

        if voice_id in available_voices:
            self.tts_voice = voice_id
            logging.info(f"üîä –ì–æ–ª–æ—Å –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: {voice_id}")
            return {"success": True, "voice": voice_id}
        else:
            return {"error": f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –≥–æ–ª–æ—Å. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {available_voices}"}

    def get_status(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Ä–µ—á–µ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã"""
        return {
            "speech_handler": {
                "initialized": True,
                "api_key_configured": bool(self.api_key),
                "model": self.model,
                "tts_voice": self.tts_voice,
                "conversation_entries": len(self.conversation_history),
                "audio_manager_connected": self.audio_manager is not None,
                "last_conversation": (
                    self.conversation_history[-1]["timestamp"]
                    if self.conversation_history else None
                )
            }
        }

    def set_tts_instructions(self, instructions):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è —Å—Ç–∏–ª—è —Ä–µ—á–∏ TTS"""
        self.config['tts_instructions'] = instructions
        logging.info(f"üé≠ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ TTS –æ–±–Ω–æ–≤–ª–µ–Ω—ã: '{instructions[:50]}...'")
        return {"success": True, "instructions": instructions}
